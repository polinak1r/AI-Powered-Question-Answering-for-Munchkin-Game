{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 75631,
          "databundleVersionId": 8348485,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polinak1r/AI-Powered-Question-Answering-for-Munchkin-Game/blob/main/AI_Powered_Question_Answering_for_Munchkin_Game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Outline: AI-Powered Question Answering for Munchkin Game\n",
        "\n",
        "1. **Imports, Model Setup, and Prompt Functions**  \n",
        "   We begin by installing and importing the necessary libraries and loading a causal language model (`microsoft/Phi-3-mini-128k-instruct`) along with its tokenizer. We define a `prompt_maker` function to construct the question-and-options prompt and a `score_options` function to compute logits for each option.\n",
        "\n",
        "2. **Kaggle Setup, Context Truncation, and Corpus Assembly**  \n",
        "   We configure Kaggle credentials to download the rules (`munchkin_rules.md`) and other files. A `truncate_tokens` function enforces `MAX_LEN = 256` to limit the context size. We then read and sentence-split the Munchkin rules, scrape and clean the official FAQ, and combine both sets of texts into a single corpus for retrieval.\n",
        "\n",
        "3. **TF-IDF Retrieval Construction**  \n",
        "   We build a TF-IDF index by tokenizing all corpus documents and computing term frequencies. A sparse TF matrix is multiplied by the IDF values, enabling quick lookups of the most relevant texts for a given query.\n",
        "\n",
        "4. **Answering Questions with Context**  \n",
        "   We load the training dataset (multiple-choice Q&A), retrieve the top-k TF-IDF matches for each question, truncate the context if needed, and pass everything to our language model via a prompt. We select the best-scoring answer based on the final token’s logits.\n",
        "\n",
        "5. **Evaluation and Submission**  \n",
        "   We compute accuracy on the training set and then apply the same pipeline to the test set, which does not have labels. Finally, we save the predicted answers (one per question) as a CSV file for submission.\n"
      ],
      "metadata": {
        "id": "w0cBXAtzHB6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "import json\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import scipy\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tokenizers import Tokenizer\n",
        "from tqdm import tqdm\n",
        "from spacy.lang.en import English"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:21:57.503559Z",
          "iopub.execute_input": "2024-05-16T13:21:57.503820Z",
          "iopub.status.idle": "2024-05-16T13:22:14.595983Z",
          "shell.execute_reply.started": "2024-05-16T13:21:57.503797Z",
          "shell.execute_reply": "2024-05-16T13:22:14.595234Z"
        },
        "trusted": true,
        "id": "3SocECSeFAR3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:22:14.597401Z",
          "iopub.execute_input": "2024-05-16T13:22:14.597816Z",
          "iopub.status.idle": "2024-05-16T13:22:14.603222Z",
          "shell.execute_reply.started": "2024-05-16T13:22:14.597791Z",
          "shell.execute_reply": "2024-05-16T13:22:14.602368Z"
        },
        "trusted": true,
        "id": "XqPIz4zXFAR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'microsoft/Phi-3-mini-128k-instruct'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             trust_remote_code=True,\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             device_map=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:22:14.604345Z",
          "iopub.execute_input": "2024-05-16T13:22:14.604670Z",
          "iopub.status.idle": "2024-05-16T13:23:03.527714Z",
          "shell.execute_reply.started": "2024-05-16T13:22:14.604640Z",
          "shell.execute_reply": "2024-05-16T13:23:03.526809Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "8d4fc1fe54d84793be741ea9fa07c5be",
            "9f787cd1debc442f961df46c0e1d3910",
            "4845a894dd644a5f8d9a997b634a34c5",
            "99f3e9f6117a4c809977f9ea4d5e68ae",
            "754d90ec2800427ca27b9ca90c52d4c1",
            "1da6d1e79a4b4463a3d0c19aea59acdf",
            "d35b4f7027ae4d5b90ad5f1adbf2bbf6",
            "0e65cb9ecc7d4f92b359229cb8d0c5c0",
            "6ba3cd3c99fe4fcb99643eebc4665079",
            "9b3313de19724abaaabd6463cf10c54c",
            "b9f417bda3fc48c4bcd296122a5b6b8a",
            "51c4f670541a4e0da73ccc0064933949",
            "f6eb2aa70ccd4c74922230e8f0e07e85",
            "cbadef5ebcc74ac09fd3cd7803735fa8"
          ]
        },
        "id": "IwuIEer6FAR3",
        "outputId": "43b6e8f5-923d-4f33-b9a2-1be7ef6e20ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d4fc1fe54d84793be741ea9fa07c5be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f787cd1debc442f961df46c0e1d3910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4845a894dd644a5f8d9a997b634a34c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f3e9f6117a4c809977f9ea4d5e68ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "754d90ec2800427ca27b9ca90c52d4c1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/3.35k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1da6d1e79a4b4463a3d0c19aea59acdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d35b4f7027ae4d5b90ad5f1adbf2bbf6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e65cb9ecc7d4f92b359229cb8d0c5c0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba3cd3c99fe4fcb99643eebc4665079"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b3313de19724abaaabd6463cf10c54c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f417bda3fc48c4bcd296122a5b6b8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51c4f670541a4e0da73ccc0064933949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6eb2aa70ccd4c74922230e8f0e07e85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbadef5ebcc74ac09fd3cd7803735fa8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_maker(question: str,\n",
        "                 contexts: list[str],\n",
        "                 options: list[str]\n",
        "                ) -> tuple[str, list[str]]:\n",
        "    prompt = 'You answering questions about a bord game given some contexts from the game rules.\\n'\n",
        "    prompt += f'The question: \"{question}\"\\n\\nTo answer this question, consider the following contexts:\\n'\n",
        "    for context in contexts:\n",
        "        prompt += f'- {context}\\n'\n",
        "    prompt += '\\nYou have the following options:\\n'\n",
        "    options_markers = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    if len(options) > len(options_markers):\n",
        "        raise ValueError('Too many options for the prompt')\n",
        "    used_option_markers = []\n",
        "    for option, option_marker in zip(options, options_markers):\n",
        "        prompt += f'{option_marker}. {option}\\n'\n",
        "        used_option_markers.append(option_marker)\n",
        "    used_options_str = ', '.join(used_option_markers)\n",
        "    prompt += f'\\nWhat option is more likely to be correct: {used_options_str}?'\n",
        "    prompt += '\\nThe most likely option is: '\n",
        "    return prompt, used_option_markers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:03.530288Z",
          "iopub.execute_input": "2024-05-16T13:23:03.530918Z",
          "iopub.status.idle": "2024-05-16T13:23:03.539190Z",
          "shell.execute_reply.started": "2024-05-16T13:23:03.530884Z",
          "shell.execute_reply": "2024-05-16T13:23:03.538441Z"
        },
        "trusted": true,
        "id": "ZKpY25E7FAR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt, choices = prompt_maker('What level should I be to win?',\n",
        "                               ['Munchkin is a card game', 'You can win by reaching level 10'],\n",
        "                               ['Level 8', 'Level 10'])\n",
        "print(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:03.540407Z",
          "iopub.execute_input": "2024-05-16T13:23:03.540689Z",
          "iopub.status.idle": "2024-05-16T13:23:11.860908Z",
          "shell.execute_reply.started": "2024-05-16T13:23:03.540665Z",
          "shell.execute_reply": "2024-05-16T13:23:11.859787Z"
        },
        "trusted": true,
        "id": "ziTL4hRvFAR4",
        "outputId": "8673b507-4c94-465a-c1c5-3c0f22f98141"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "You answering questions about a bord game given some contexts from the game rules.\nThe question: \"What level should I be to win?\"\n\nTo answer this question, consider the following contexts:\n- Munchkin is a card game\n- You can win by reaching level 10\n\nYou have the following options:\nA. Level 8\nB. Level 10\n\nWhat option is more likely to be correct: A, B?\nThe most likely option is: \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This form of prompt allows using logits of next token for classification, since the next token supposed to be a single letter poining to the correct option."
      ],
      "metadata": {
        "id": "7bBGDJZgFAR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def score_options(prompt: str,\n",
        "                  options: list[str],\n",
        "                  model: torch.nn.Module,\n",
        "                  tokenizer: Tokenizer,\n",
        "                  device) -> torch.Tensor:\n",
        "    token_ids = tokenizer(prompt, return_tensors='pt')['input_ids']\n",
        "    outs = model(token_ids.to(device))\n",
        "    opt_tokens = []\n",
        "    for opt in options:\n",
        "        opt_token_tens = tokenizer(opt, return_tensors='pt',add_special_tokens=False)['input_ids'][0]\n",
        "        assert len(opt_token_tens) == 1, 'Only one token option is supported'\n",
        "        opt_token = opt_token_tens[0]\n",
        "        opt_tokens.append(opt_token)\n",
        "    log_probs = outs.logits[0, -1, opt_tokens].cpu()\n",
        "    return log_probs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:11.862536Z",
          "iopub.execute_input": "2024-05-16T13:23:11.862896Z",
          "iopub.status.idle": "2024-05-16T13:23:11.966268Z",
          "shell.execute_reply.started": "2024-05-16T13:23:11.862865Z",
          "shell.execute_reply": "2024-05-16T13:23:11.965127Z"
        },
        "trusted": true,
        "id": "i8JJGolmFAR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choices_scores = score_options(prompt, choices, model, tokenizer, device)\n",
        "choice_idx = choices_scores.argmax().item()\n",
        "choice = choices[choice_idx]\n",
        "print(prompt + choice)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:11.967543Z",
          "iopub.execute_input": "2024-05-16T13:23:11.968384Z",
          "iopub.status.idle": "2024-05-16T13:23:13.595827Z",
          "shell.execute_reply.started": "2024-05-16T13:23:11.968352Z",
          "shell.execute_reply": "2024-05-16T13:23:13.594910Z"
        },
        "trusted": true,
        "id": "g3NPHADZFAR4",
        "outputId": "18e79563-1ac5-4978-c479-eaa7cdf01de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "You answering questions about a bord game given some contexts from the game rules.\nThe question: \"What level should I be to win?\"\n\nTo answer this question, consider the following contexts:\n- Munchkin is a card game\n- You can win by reaching level 10\n\nYou have the following options:\nA. Level 8\nB. Level 10\n\nWhat option is more likely to be correct: A, B?\nThe most likely option is: B\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite the possible context size of current models is large as thousands of tokens, we limit the maximum number of tokens in context. This makes the task more challenging but in the same time it becomes closer to real-world applications. All contexts we use must undergo truncation procedure. MAX_LEN variable must not be changed."
      ],
      "metadata": {
        "id": "06duupvGFAR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256\n",
        "\n",
        "def truncate_tokens(contexts: list[str]) -> str:\n",
        "    total_tokens = 0\n",
        "    turncated_contexts = []\n",
        "    for ctx in contexts:\n",
        "        ctx_tokens = tokenizer(ctx, add_special_tokens=False)['input_ids']\n",
        "        total_tokens += len(ctx_tokens)\n",
        "        if total_tokens > MAX_LEN:\n",
        "            ctx = tokenizer.decode(ctx_tokens)\n",
        "            return turncated_contexts + [ctx]\n",
        "        else:\n",
        "            turncated_contexts.append(ctx)\n",
        "    return turncated_contexts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:13.597056Z",
          "iopub.execute_input": "2024-05-16T13:23:13.597641Z",
          "iopub.status.idle": "2024-05-16T13:23:13.603435Z",
          "shell.execute_reply.started": "2024-05-16T13:23:13.597599Z",
          "shell.execute_reply": "2024-05-16T13:23:13.602575Z"
        },
        "trusted": true,
        "id": "lCIhxvl4FAR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truncate_tokens(['something ' * 32, 'other ' * 256, 'another ' * 32])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:13.604711Z",
          "iopub.execute_input": "2024-05-16T13:23:13.605059Z",
          "iopub.status.idle": "2024-05-16T13:23:28.551295Z",
          "shell.execute_reply.started": "2024-05-16T13:23:13.605029Z",
          "shell.execute_reply": "2024-05-16T13:23:28.550372Z"
        },
        "trusted": true,
        "id": "hE9ZRWgxFAR5",
        "outputId": "7bb33bf3-3cd5-48ca-b6e1-234df8a109ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-05-16 13:23:17.388995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-16 13:23:17.389100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-16 13:23:17.662613: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['something something something something something something something something something something something something something something something something something something something something something something something something something something something something something something something something ',\n 'other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other ']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assemble the Corpus for Retrieval"
      ],
      "metadata": {
        "id": "L5Ei4AScFAR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "WyhLN-12IDZI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"kaggle.json\", \"r\") as f:\n",
        "    creds = json.load(f)"
      ],
      "metadata": {
        "id": "UVlv9kFOIUtv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]"
      ],
      "metadata": {
        "id": "YM7TeDdyIbE6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ABqhJ3mdIihF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw2 -f munchkin_rules.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jf75-nNImXQ",
        "outputId": "583e93b0-b672-4efc-dcb8-55022a069990"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading munchkin_rules.md to /content\n",
            "\r  0% 0.00/25.7k [00:00<?, ?B/s]\n",
            "\r100% 25.7k/25.7k [00:00<00:00, 36.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('munchkin_rules.md') as fp:\n",
        "    rules = fp.read()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:28.555497Z",
          "iopub.execute_input": "2024-05-16T13:23:28.555824Z",
          "iopub.status.idle": "2024-05-16T13:23:28.567977Z",
          "shell.execute_reply.started": "2024-05-16T13:23:28.555801Z",
          "shell.execute_reply": "2024-05-16T13:23:28.567102Z"
        },
        "trusted": true,
        "id": "_8eXsyxPFAR5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rules[:1000])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:28.569321Z",
          "iopub.execute_input": "2024-05-16T13:23:28.569647Z",
          "iopub.status.idle": "2024-05-16T13:23:28.595017Z",
          "shell.execute_reply.started": "2024-05-16T13:23:28.569613Z",
          "shell.execute_reply": "2024-05-16T13:23:28.594072Z"
        },
        "trusted": true,
        "id": "PjogYaPnFAR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f6afe1-9037-4888-d866-9f3831217ee4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Munchkin brings you the essence of the dungeon-crawling experience... without all that messy roleplaying!\n",
            "This game includes 168 cards, one six-sided die, and these rules. Three to six can play. You will need 10 tokens (coins, poker chips, whatever – or any gadget that counts to 10) for each player.\n",
            "\n",
            "# Setup\n",
            "Divide the cards into the Door deck and the Treasure deck. Shuffle both decks. Deal four cards from each deck to each player.\n",
            "\n",
            "# Card Management\n",
            "Keep separate face-up discard piles for the two decks. You may not look through the discards unless you play a card that allows you to! When a deck runs out, reshuffle its discards. In Play: These are the cards on the table in front of you, showing your Race and Class (if any) and the Items you are carrying. Continuing Curses and some other cards also stay on the table after you play them. Cards in play are public information and must be visible to the other players.\n",
            "Your Hand: Cards in your hand are not in play. They don’t help you, but t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()\n",
        "nlp.add_pipe(\"sentencizer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:28.595989Z",
          "iopub.execute_input": "2024-05-16T13:23:28.596236Z",
          "iopub.status.idle": "2024-05-16T13:23:28.902295Z",
          "shell.execute_reply.started": "2024-05-16T13:23:28.596215Z",
          "shell.execute_reply": "2024-05-16T13:23:28.901322Z"
        },
        "trusted": true,
        "id": "u7luzx6cFAR5",
        "outputId": "b5a0d21c-8876-407f-9de5-6407b1b07315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7c1e3f7c9dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rules_texts = [s.text.strip() for s in nlp(rules).sents]\n",
        "rules_texts[:20]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:28.903667Z",
          "iopub.execute_input": "2024-05-16T13:23:28.904233Z",
          "iopub.status.idle": "2024-05-16T13:23:29.036434Z",
          "shell.execute_reply.started": "2024-05-16T13:23:28.904200Z",
          "shell.execute_reply": "2024-05-16T13:23:29.035578Z"
        },
        "trusted": true,
        "id": "ufm1heVYFAR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c101e8f6-4672-40df-e738-c5e882c00ef4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Munchkin brings you the essence of the dungeon-crawling experience... without all that messy roleplaying!',\n",
              " 'This game includes 168 cards, one six-sided die, and these rules.',\n",
              " 'Three to six can play.',\n",
              " 'You will need 10 tokens (coins, poker chips, whatever – or any gadget that counts to 10) for each player.',\n",
              " '# Setup\\nDivide the cards into the Door deck and the Treasure deck.',\n",
              " 'Shuffle both decks.',\n",
              " 'Deal four cards from each deck to each player.',\n",
              " '# Card Management\\nKeep separate face-up discard piles for the two decks.',\n",
              " 'You may not look through the discards unless you play a card that allows you to!',\n",
              " 'When a deck runs out, reshuffle its discards.',\n",
              " 'In Play: These are the cards on the table in front of you, showing your Race and Class (if any) and the Items you are carrying.',\n",
              " 'Continuing Curses and some other cards also stay on the table after you play them.',\n",
              " 'Cards in play are public information and must be visible to the other players.',\n",
              " 'Your Hand: Cards in your hand are not in play.',\n",
              " 'They don’t help you, but they can’t be taken away except by cards that specifically affect “your hand.”',\n",
              " 'At the end of your turn, you may have no more than five cards in your hand (see Charity, p. 2).Cards in play may not be returned to your hand – they must be discarded or traded if you want to get rid of them.',\n",
              " '# Conflicts Between Cards and Rules\\nThis rulesheet gives the general rules.',\n",
              " 'Many cards add special rules, so in most cases when the rulesheet disagrees with a card, follow the card.',\n",
              " 'However, ignore any card effect that might seem to contradict one of the rules listed below unless the card explicitly says it supersedes that rule!',\n",
              " '1.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq_link = 'https://munchkin.game/gameplay/faq/'\n",
        "response = requests.get(faq_link)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "faq_document = soup.find('div', id='main').get_text()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.037867Z",
          "iopub.execute_input": "2024-05-16T13:23:29.038261Z",
          "iopub.status.idle": "2024-05-16T13:23:29.601758Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.038225Z",
          "shell.execute_reply": "2024-05-16T13:23:29.601049Z"
        },
        "trusted": true,
        "id": "_Y6Fz0BVFAR5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq_document = re.sub('\\n\\n+', '\\n\\n', faq_document)\n",
        "print(faq_document[:1000])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.607893Z",
          "iopub.execute_input": "2024-05-16T13:23:29.608289Z",
          "iopub.status.idle": "2024-05-16T13:23:29.617766Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.608259Z",
          "shell.execute_reply": "2024-05-16T13:23:29.617020Z"
        },
        "trusted": true,
        "id": "1KzI4tnBFAR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d033df27-b43d-46a7-d24f-36b2320c7d29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "Frequently Asked Questions for all Munchkin Games, Supplements, and Accessories\n",
            "Updated April 20, 2020\n",
            "If you can't find your answer here, check the errata, to make sure we didn't make a mistake.\n",
            "If you want to check the FAQ for a specific game, you can head straight to the Table of Contents.\n",
            "General Notes\n",
            "Every Munchkin set puts its own spin on the game, but they do have many rules in common. This first section deals with some of those.\n",
            "All answers in this FAQ refer to editions of Munchkin published in 2010 or later. If you have a game published before then, look at the 2010 Munchkin Change Log for a detailed list of changes, set by set.\n",
            "June 2018 update: We are no longer supporting the Epic Munchkin rules, so all answers here (outside of the Epic Munchkin section itself) assume that you are playing a regular game ending at Level 10. See that section for more details.\n",
            "July 2018 update: We have made two global rule updates to all Munchkin games, and these updates will affect som\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq_texts = faq_document.split('\\n')\n",
        "faq_texts = [text for text in faq_texts if text.strip()]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.618683Z",
          "iopub.execute_input": "2024-05-16T13:23:29.618948Z",
          "iopub.status.idle": "2024-05-16T13:23:29.627582Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.618925Z",
          "shell.execute_reply": "2024-05-16T13:23:29.626860Z"
        },
        "trusted": true,
        "id": "vrdee7c7FAR6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# faq_texts[170:180]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.628574Z",
          "iopub.execute_input": "2024-05-16T13:23:29.628817Z",
          "iopub.status.idle": "2024-05-16T13:23:29.637826Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.628795Z",
          "shell.execute_reply": "2024-05-16T13:23:29.637006Z"
        },
        "trusted": true,
        "id": "rAj5enpiFAR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# faq_texts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.638904Z",
          "iopub.execute_input": "2024-05-16T13:23:29.639243Z",
          "iopub.status.idle": "2024-05-16T13:23:29.649307Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.639211Z",
          "shell.execute_reply": "2024-05-16T13:23:29.648596Z"
        },
        "trusted": true,
        "id": "LuW0CEy1FAR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq_texts_clear = []\n",
        "for i in tqdm(range(len(faq_texts))):\n",
        "    sent = faq_texts[i]\n",
        "    if i <44:\n",
        "        faq_texts_clear.append(sent)\n",
        "    if i > 143:\n",
        "        if sent[:2] == 'Q.' and faq_texts[i+1][:2] == 'A.':\n",
        "            faq_texts_clear.append(sent[2:] + \" \" + faq_texts[i+1][2:])\n",
        "\n",
        "print(len(faq_texts), len(faq_texts_clear))\n",
        "faq_texts = faq_texts_clear"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.650177Z",
          "iopub.execute_input": "2024-05-16T13:23:29.650474Z",
          "iopub.status.idle": "2024-05-16T13:23:29.665561Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.650452Z",
          "shell.execute_reply": "2024-05-16T13:23:29.664668Z"
        },
        "trusted": true,
        "id": "S5zD05ndFAR6",
        "outputId": "d19f63f0-694a-4887-f51c-4964ce53a6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 1439/1439 [00:00<00:00, 568377.76it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1439 585\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our corpus for retrieval will be just a concatenation of `faq_texts` and `rules_texts`. We will search over it given our question, retrieve the most relevant texts and pass them to the model as context to answer the question."
      ],
      "metadata": {
        "id": "DA45issQFAR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = faq_texts + rules_texts\n",
        "len(corpus)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.666976Z",
          "iopub.execute_input": "2024-05-16T13:23:29.667556Z",
          "iopub.status.idle": "2024-05-16T13:23:29.672841Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.667531Z",
          "shell.execute_reply": "2024-05-16T13:23:29.672062Z"
        },
        "trusted": true,
        "id": "-epmE0-sFAR6",
        "outputId": "08ad7bc9-aeb9-4987-9440-55877733abcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "888"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF retrieval\n",
        "\n",
        "In this section we build a simple TF-IDF retrieval method."
      ],
      "metadata": {
        "id": "YJNBG50YFAR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = defaultdict(Counter)\n",
        "term_counts = Counter()\n",
        "\n",
        "tok_list = []\n",
        "for text_num, text in enumerate(corpus):\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    for tok in tokens:\n",
        "        index[tok][text_num] += 1\n",
        "        term_counts[tok] += 1\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.673863Z",
          "iopub.execute_input": "2024-05-16T13:23:29.674109Z",
          "iopub.status.idle": "2024-05-16T13:23:29.913620Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.674088Z",
          "shell.execute_reply": "2024-05-16T13:23:29.912853Z"
        },
        "trusted": true,
        "id": "fLc1baTzFAR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_texts = len(corpus)\n",
        "num_terms = len(index)\n",
        "\n",
        "term_to_idx = {t: n for n, (t, _) in enumerate(term_counts.most_common())}\n",
        "\n",
        "df_counts = []\n",
        "df_doc_idxs = []\n",
        "df_term_idxs = []\n",
        "for term, text_counts in index.items():\n",
        "    for text_num, count in text_counts.items():\n",
        "        df_counts.append(count)\n",
        "        df_doc_idxs.append(text_num)\n",
        "        df_term_idxs.append(term_to_idx[term])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.914648Z",
          "iopub.execute_input": "2024-05-16T13:23:29.914890Z",
          "iopub.status.idle": "2024-05-16T13:23:29.939249Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.914868Z",
          "shell.execute_reply": "2024-05-16T13:23:29.938558Z"
        },
        "trusted": true,
        "id": "7Bs2hA-VFAR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_mat = scipy.sparse.coo_array(\n",
        "    (df_counts, (df_doc_idxs, df_term_idxs)),\n",
        "    shape=(num_texts, num_terms)\n",
        ").tocsr()\n",
        "\n",
        "idf = np.log(num_texts / (tf_mat > 0).sum(0)).reshape(1, -1)\n",
        "tfidf_mat = tf_mat * idf\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.940229Z",
          "iopub.execute_input": "2024-05-16T13:23:29.940486Z",
          "iopub.status.idle": "2024-05-16T13:23:29.980273Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.940464Z",
          "shell.execute_reply": "2024-05-16T13:23:29.979612Z"
        },
        "trusted": true,
        "id": "4G0keEpFFAR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_tf_vec(query, tokenizer, num_terms):\n",
        "    q_vec = np.zeros(num_terms, dtype=int)\n",
        "    toks = tokenizer.tokenize(query.lower())\n",
        "    for tok in toks:\n",
        "        if tok in term_to_idx:\n",
        "            q_vec[term_to_idx[tok]] += 1\n",
        "    return q_vec\n",
        "\n",
        "def tfidf_dot_product_for_query(q, tfidf_mat, idf, tokenizer):\n",
        "    num_terms = tfidf_mat.shape[1]\n",
        "    query_vec = get_query_tf_vec(q, tokenizer, num_terms)\n",
        "    return tfidf_mat @ (query_vec * idf.reshape(-1))\n",
        "\n",
        "\n",
        "def get_top_k_texts_for_query(q, k, corpus, tfidf_mat, idf, tokenizer):\n",
        "    if k == 0:\n",
        "        return []\n",
        "    top_k_indices = np.argsort(tfidf_dot_product_for_query(q, tfidf_mat, idf, tokenizer))[-k:]\n",
        "    return [corpus[i] for i in top_k_indices]\n",
        "\n",
        "\n",
        "top_k = 5\n",
        "contexts = get_top_k_texts_for_query('What level should I be to win?', top_k, corpus, tfidf_mat, idf, tokenizer)\n",
        "contexts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.981280Z",
          "iopub.execute_input": "2024-05-16T13:23:29.981564Z",
          "iopub.status.idle": "2024-05-16T13:23:29.995617Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.981540Z",
          "shell.execute_reply": "2024-05-16T13:23:29.994764Z"
        },
        "trusted": true,
        "id": "RpbGeJ4cFAR7",
        "outputId": "5bab04b3-9d7a-4956-9cf9-261e1359acbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[\" Can I play Duck of Earl if I am Level 1 and can't lose a level? What if I'm Level 9 and can't gain a level unless I kill a monster? And what if I'm using a special trick die so I'm guaranteed to roll a 6?  You can still play the card in all these circumstances, but you don't lose/gain the level. Normally, using a trick die would be very much against the spirit of the rules, but the text on this card leaves that door wide open. Good . . . luck?\",\n 'You cannot use a card or ability to force someone to help you if the combat is for the win. If you have forced someone to help and then the combat becomes one for the win, your helper is kicked out of the fight without penalty and you must fight alone (or ask someone to help – good luck with that). On the other hand, if you force someone to help and they would win the game, they get to stay in . . . be careful whose help you accept!',\n ' The Dungeon of Extra Effort says that to win the game we must make it to Level 11, but that Level 10 and 11 are treated the same way. Does this mean I can play a Go Up a Level card to go from Level 9 to 10?  No, you cannot play a Go Up a Level to go to Level 10. This Dungeon does not change the rules for reaching Level 10 (see Important Note #1); it just adds a Level 11 beyond it.',\n \" I just killed a monster to reach Level 10. My opponent played Trojan Horse and the Plutonium Dragon and said I couldn't level up (and therefore win the game) until I killed the Dragon. I say that I killed my monster, and even if I didn't get the Treasure, I win because I reached Level 10. Who's right?   Congratulations on your victory! Trojan Horse cancels the Treasure but not the levels from one combat and immediately starts a new one. If the result of the first combat brought you to Level 10, the game is over and Trojan Horse can't be played.\",\n 'Players may not be forced to help someone else in a combat that is for the win. If a player is forced to help someone in a combat and it later becomes a combat for the win, the helper is kicked out of the fight without penalty. This rule does not apply to voluntary helpers, who should have thought harder about what they were getting into. It also does not apply in the situation where the helper could win the game (Elves, mostly, but other cards can set up this situation); be careful when you choose a helper!']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the truncated version is:"
      ],
      "metadata": {
        "id": "D5ZjEO4WFAR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# truncate_tokens(contexts)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:29.996775Z",
          "iopub.execute_input": "2024-05-16T13:23:29.997043Z",
          "iopub.status.idle": "2024-05-16T13:23:30.004558Z",
          "shell.execute_reply.started": "2024-05-16T13:23:29.997020Z",
          "shell.execute_reply": "2024-05-16T13:23:30.003842Z"
        },
        "trusted": true,
        "id": "waSweF-HFAR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "Below is the code for loading the train dataset and computation of accuracy metric for our solution."
      ],
      "metadata": {
        "id": "t19Vqzi7FAR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-nup-2024-hw2 -f train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fZJN4DeKSO4",
        "outputId": "1fe57240-7ceb-42f4-afef-b2d2c1b868aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train.csv to /content\n",
            "\r  0% 0.00/172k [00:00<?, ?B/s]\n",
            "\r100% 172k/172k [00:00<00:00, 46.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = pd.read_csv('train.csv')\n",
        "ds_train['options'] = ds_train['options'].map(eval)\n",
        "ds_train = ds_train.to_dict('records')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:30.005547Z",
          "iopub.execute_input": "2024-05-16T13:23:30.005865Z",
          "iopub.status.idle": "2024-05-16T13:23:30.059263Z",
          "shell.execute_reply.started": "2024-05-16T13:23:30.005834Z",
          "shell.execute_reply": "2024-05-16T13:23:30.058516Z"
        },
        "trusted": true,
        "id": "I3WXAxVeFAR8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train[:2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:30.064156Z",
          "iopub.execute_input": "2024-05-16T13:23:30.064403Z",
          "iopub.status.idle": "2024-05-16T13:23:30.067944Z",
          "shell.execute_reply.started": "2024-05-16T13:23:30.064372Z",
          "shell.execute_reply": "2024-05-16T13:23:30.067019Z"
        },
        "trusted": true,
        "id": "J_c603APFAR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6f656b-92a3-4a6a-8d9d-0059b2a00de2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 0,\n",
              "  'question': 'What does the instruction \"Gotta sing it!\" on Make Bacon Pancakes refer to?',\n",
              "  'options': ['The recipe of making bacon pancakes',\n",
              "   'The tune of a popular song',\n",
              "   'The rules of the game',\n",
              "   'The name of the monster'],\n",
              "  'answer': 1},\n",
              " {'id': 1,\n",
              "  'question': 'When is it appropriate to utilize the Buried Treasure ability of the Pirate?',\n",
              "  'options': ['After defeating a monster in combat.',\n",
              "   'When you have not encountered a monster during your turn.',\n",
              "   'When you are Running Away from a monster.',\n",
              "   'During the Loot The Room phase, after Looking For Trouble.'],\n",
              "  'answer': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "correct = 0\n",
        "total = len(ds_train)\n",
        "mean_context_size = 0\n",
        "max_context_size = 0\n",
        "for sample in tqdm(ds_train):\n",
        "    question = sample['question']\n",
        "    options = sample['options']\n",
        "    contexts = get_top_k_texts_for_query(question, k, corpus, tfidf_mat, idf, tokenizer)\n",
        "    context_size = sum(len(tokenizer.tokenize(ctx)) for ctx in contexts)\n",
        "    mean_context_size += context_size / len(ds_train)\n",
        "    max_context_size = max(max_context_size, context_size)\n",
        "    contexts = truncate_tokens(contexts)\n",
        "    prompt, choices = prompt_maker(question,\n",
        "                                   contexts,\n",
        "                                   options)\n",
        "\n",
        "\n",
        "    choices_scores = score_options(prompt, choices, model, tokenizer, device)\n",
        "    choice_idx = choices_scores.argmax().item()\n",
        "    choice = choices[choice_idx]\n",
        "    correct += choice_idx == sample['answer']\n",
        "print(f'Top-k: {k}\\nAccuracy: {correct / total:.3f}\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:23:30.069087Z",
          "iopub.execute_input": "2024-05-16T13:23:30.069367Z",
          "iopub.status.idle": "2024-05-16T13:25:34.898723Z",
          "shell.execute_reply.started": "2024-05-16T13:23:30.069332Z",
          "shell.execute_reply": "2024-05-16T13:25:34.897994Z"
        },
        "trusted": true,
        "id": "jDi7Z4BSFAR8",
        "outputId": "c5bbe048-c561-4f36-aaf9-faf344e2a84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 537/537 [02:04<00:00,  4.30it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Top-k: 3\nAccuracy: 0.702\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.693"
      ],
      "metadata": {
        "id": "DejlCou-FAR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Set and Submission\n",
        "\n",
        "The only difference of the test set from the train set is that it does not provide labels."
      ],
      "metadata": {
        "id": "YUq8hHJqFAR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test = pd.read_csv('test.csv')\n",
        "ds_test['options'] = ds_test['options'].map(eval)\n",
        "ds_test = ds_test.to_dict('records')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:25:34.899767Z",
          "iopub.execute_input": "2024-05-16T13:25:34.900012Z",
          "iopub.status.idle": "2024-05-16T13:25:34.932190Z",
          "shell.execute_reply.started": "2024-05-16T13:25:34.899991Z",
          "shell.execute_reply": "2024-05-16T13:25:34.931551Z"
        },
        "trusted": true,
        "id": "Oj9cGVzjFAR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ds_test[:2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:25:34.933080Z",
          "iopub.execute_input": "2024-05-16T13:25:34.933312Z",
          "iopub.status.idle": "2024-05-16T13:25:34.937286Z",
          "shell.execute_reply.started": "2024-05-16T13:25:34.933291Z",
          "shell.execute_reply": "2024-05-16T13:25:34.936342Z"
        },
        "trusted": true,
        "id": "3nribWFDFAR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "submission = []\n",
        "for sample in tqdm(ds_test):\n",
        "    question = sample['question']\n",
        "    options = sample['options']\n",
        "    id_sample = sample['id']\n",
        "    contexts = get_top_k_texts_for_query(question, k, corpus, tfidf_mat, idf, tokenizer)\n",
        "    contexts = truncate_tokens(contexts)\n",
        "    prompt, choices = prompt_maker(question,\n",
        "                                   contexts,\n",
        "                                   options)\n",
        "\n",
        "    choices_scores = score_options(prompt, choices, model, tokenizer, device)\n",
        "    choice_idx = choices_scores.argmax().item()\n",
        "    submission.append({'id': id_sample, 'answer': choice_idx})\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:25:34.938175Z",
          "iopub.execute_input": "2024-05-16T13:25:34.938451Z",
          "iopub.status.idle": "2024-05-16T13:27:41.817353Z",
          "shell.execute_reply.started": "2024-05-16T13:25:34.938422Z",
          "shell.execute_reply": "2024-05-16T13:27:41.816416Z"
        },
        "trusted": true,
        "id": "pcS-mLqAFAR8",
        "outputId": "e17f78f0-6ef0-43a0-f539-e109e91451e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 538/538 [02:06<00:00,  4.24it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(submission)\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:27:41.818461Z",
          "iopub.execute_input": "2024-05-16T13:27:41.818721Z",
          "iopub.status.idle": "2024-05-16T13:27:41.834384Z",
          "shell.execute_reply.started": "2024-05-16T13:27:41.818699Z",
          "shell.execute_reply": "2024-05-16T13:27:41.833486Z"
        },
        "trusted": true,
        "id": "dg402Ex0FAR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}